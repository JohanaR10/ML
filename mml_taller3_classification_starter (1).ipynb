{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5bJgVq8tSo4"
   },
   "source": [
    "## Mastering Machine Learning 2025\n",
    "\n",
    "Taller 3: clasificación de texto usando modelos de lenguaje\n",
    "\n",
    "Antes de iniciar abra este cuaderno en Google Colab y habilite la ejecución con GPU:\n",
    "- En el menú Entorno de ejecución seleccione Cambiar tipo entorno de ejecución.\n",
    "- Asegúrese de tener seleccionado Python 3.\n",
    "- Como Acelerador de hardware seleccione GPU T4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBK5R_V-tbRW"
   },
   "source": [
    "Instale las dependencias para asegurar la correcta ejecución del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIf7rZpskmIT"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu7H_VIKuYUr"
   },
   "source": [
    "Usaremos el dataset de reseñas de pelítuclas de Rotten Tomatoes, disponible en Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSDm6VmFGvot"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load our data\n",
    "data = load_dataset('cornell-movie-review-data/rotten_tomatoes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqiI8nS0uhE8"
   },
   "source": [
    "Exploremos los datos, que contienen conjuntos de entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3l7ehNPk9Dp"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-EPdG1Eu_tZ"
   },
   "source": [
    "Exploremos algunos registros, que contienen tanto el texto de la reseña, como la etiqueta, positiva o negativa, de acuerdo con el sentimiento de la reseña."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTw94CIzlKWn"
   },
   "outputs": [],
   "source": [
    "data[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_o6PnAqwX5H"
   },
   "outputs": [],
   "source": [
    "data[\"train\"][5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pJlJ0iZxGiS"
   },
   "source": [
    "### Clasificación usando un modelo entrenado para una tarea específica\n",
    "\n",
    "Ahora vamos a clasificar las reseñas de películas usando un modelo pre-entrenado para la **tarea específica** de **análisis de sentimiento**. Específicamente, usaremos el modelos RoBERTa (https://huggingface.co/FacebookAI/roberta-base) que es un modelo BERT entrenado de manera auto-supervisada empleando tweets en inglés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRdOcMkklOPB"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Path del modelo\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Cargar el modelo en un pipeline para ejecutar primero el tokenizador\n",
    "# (mismo del modelo) y luego el modelo\n",
    "pipe = pipeline(\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    return_all_scores=True,\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlw1kgBylPKh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "y_pred = []\n",
    "# Aplicamos el pipeline a cada elemento del dataset y obtenemos un output\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\")), total=len(data[\"test\"])):\n",
    "  # con base en el output calculamos el puntaje positivo y negativo\n",
    "  negative_score = output[0][\"score\"]\n",
    "  positive_score = output[2][\"score\"]\n",
    "  # asignamos la clase positiva o negativa dependiendo de los puntajes obtenidos\n",
    "  assignment = np.argmax([negative_score, positive_score])\n",
    "  y_pred.append(assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk0QvjU2zfhJ"
   },
   "source": [
    "Definimos una función que genera el reporte de clasificación con las métricas más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_osgStSwlbMo"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    \"\"\"Create and print the classification report\"\"\"\n",
    "    performance = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
    "    )\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihBX_BPgzoXq"
   },
   "source": [
    "Usamos la función con las predicciones obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss14iHyUlk_i"
   },
   "outputs": [],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vye5TGZ-0BTw"
   },
   "source": [
    "### Clasificación usando un modelo de embeddings\n",
    "\n",
    "Ahora vamos a clasificar las reseñas de películas usando un modelo de embeddings que no ha sido pre-entrenado para alguna tarea. Específicamente, usaremos el paquete sentence_transformers y el modelo all-mpnet-base-v2 (https://huggingface.co/sentence-transformers/all-mpnet-base-v2) que mapea frases y párrafos a un espacio de 768 dimensiones, una representación que puede usarse para tareas de clasificación, clustering, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SZwsQ8BlsHb"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargamos el modelo\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "# Convertimos los testos de las reseñas a embeddings\n",
    "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
    "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tsza9Jxi1U61"
   },
   "source": [
    "Si revisamos el tamaño de los datos obtenidos podemodes observar que cada texto ha sido transformado a un vector de 768 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bp-0t29lvbJ"
   },
   "outputs": [],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UHdmk841evq"
   },
   "source": [
    "Ahora usaremos esta representación numérica de los textos y las etiquetas para entrenar un modelo de clasificación (regresión logística). Note que usamos los datos de entrenamiento para esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Kwu6TbJlyIi"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdwVFjjE13B0"
   },
   "source": [
    "Ahora evaluamos el desempeño del modelo de clasificación usando los datos de prueba e imprimimos el informe con las métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vxBj6zdl27L"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_embeddings)\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5et6zfs2Ogs"
   },
   "source": [
    "### Clasificación sin etiquetas - Zero-shot classification\n",
    "\n",
    "Para evaluar el desempeño de los modelos anteriores usamos etiquetas para indicar si las reseñas eran positivas o negativas. Esta tarea típicamente es muy costosa y puede hacer infactible un proyecto. En esta sección exploramos una alternativa empleando modelos preentrenados de embeddings.\n",
    "\n",
    "Usaremos el mismo modelo de embeddings usado anterioremente, el modelo all-mpnet-base-v2 (https://huggingface.co/sentence-transformers/all-mpnet-base-v2) que mapea frases y párrafos a un espacio de 768 dimensiones, una representación que puede usarse para tareas de clasificación, clustering, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeQJZtxE3pVD"
   },
   "source": [
    "El primer paso es encontrar una representación de las **etiquetas de las clases** en el espacio del embedding. En este caso las etiquetas se refieren a reseñas positivas y negativas, así que usamos un texto para cada clase que las represente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEYXKEiel9pO"
   },
   "outputs": [],
   "source": [
    "label_embeddings = model.encode([\"A negative review\",  \"A positive review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laQ0Pfpi4M3e"
   },
   "source": [
    "Ahora importamos la función de cosine_similarity para calcular la similitud de coseno entre un par de vectores. Si los vectores son iguales (apuntan en la misma dirección), el ángulo entre ellos es 0 y su coseno es 1. Por el contrario, si los vectores son diferentes, el ángulo es diferente a cero y el coseno es menor a 1, indicando una menor similitud.\n",
    "\n",
    "Calculamos entonces la matriz de similtud entre los embeddings de los casos de prueba y los embeddings de las etiquetas que definimos arriba. Y hacemos las predicciones seleccionando la clase que presenta la mayor similitud para cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qx-0yLkzmAHf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY3qhfjv5OxN"
   },
   "source": [
    "Evaluamos el desempeño usando el mismo reporte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdzZFP8WmCa1"
   },
   "outputs": [],
   "source": [
    "\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOgYdackUPoqNsW6E1g6SaQ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
